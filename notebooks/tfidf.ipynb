{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Using Term Frequency - Inverse Document Frequency\n",
    "To create an accurate predictive model which determines how well someone did on their virtual internship there are two potential general methods:\n",
    "* Using the provided tabular data\n",
    "* Use a numeric representation of the chat transcripts\n",
    "\n",
    "Although interpreting written text is far more difficult than creating a tabular classifier, it has greater overall potential.\n",
    "This is because the given tabular data does not provide enough information to make an informative decision on how well or badly someone faired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Before we can begin creating models to predict peoples scores we have to ensure that the data is cleaned and interpretable.\n",
    "\n",
    "The process begins with removing messages sent by the mentor.\n",
    "These are preset with an average rating of 4 to avoid modifying any average statistics run on the dataset.\n",
    "However, they do not add any value to the analysis and further skew the datasets mode towards the average mean result.\n",
    "\n",
    "Secondly we oversample the minority classes which have less samples.\n",
    "This mitigates our models seeing very few highly-rated and low-rated scores, whilst at the same time a very very large number of average ratings (class imbalance).\n",
    "To finish off we ensure that this though does not happen to the test dataset, as we want to see how it fairs on the actual problem (having duplicates does help).\n",
    "We utilise random state seeds to ensure that this all happens the exact same way each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df = df[df[\"RoleName\"] != \"Mentor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "x_resampled, y_resampled = ros.fit_resample(df[[\"content\"]], df[\"OutcomeScore\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_resampled[\"content\"], y_resampled, train_size=0.8, random_state=0)\n",
    "_, x_test, _, y_test = train_test_split(df[\"content\"], df[\"OutcomeScore\"], train_size=0.8, random_state=0) # test on imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We will test a variety of models to see how different models fair.\n",
    "Models include logistic regression (baseline),  naive bays, k-nearest neighbors, decision trees and ensemble models such as random forests and (normal/extreme) gradient boosting.\n",
    "The selection is designed to accentuate which types of models are most likely to work well for classification of grades based on sparse text.\n",
    "\n",
    "\n",
    "Upon first tests, all models go through a hyperparameter optimisation process.\n",
    "Instead of tuning all hyperparameters, a small selection are chosen per model which either alter how the models function (e.g. optimisation routines) or how conservative they are (e.g. max depth).\n",
    "Hyperparameter values are randomly selected within their specified range and in the end to combination which produces the highest weighted f1 score is chosen.\n",
    "F1 scores are prefered over accuracy simple to avoid situations where either precission or recall is high whilst the other low.\n",
    "Due to the large computational and time cost in hyperparameter selection, the process is only rerun for models where it resulted in sizable improvementns (based on further evaluation).\n",
    "This is the case for the baseline logistic regression model.\n",
    "Other optimisation routines are commented out and the basic pipeline is selected instead.\n",
    "\n",
    "\n",
    "Note that although these models aren't trained using K-Fold cross validation, this happens later on in the evaluation section for the best and worst model.\n",
    "This statistically ensures that the results are sound and not simply due to overfitting or a randomly easy/hard dataset (for example one with very few examples of high scoring messages will struggle on the test set).\n",
    "\n",
    "\n",
    "We will prioritise testing two types of models:\n",
    "* Random Forests - An Ensemble of Decision Trees\n",
    "* Logistic Regression\n",
    "\n",
    "\n",
    "To simplify the creation and usage of these models we will compose several pipelines.\n",
    "Each of these will start with a TF-IDF vectoriser (to transform the text into a matrix of numbers) and after this proceed with a classifier (like logistic regression).\n",
    "Term Frequency - Inverse Document Frequency (TF-IDF) models provide a standard way to go from text to a numeric vector representation of data.\n",
    "This works by first calculating the number of times each word is used in total and in every separate document.\n",
    "This can be divided and used as numeric data in future models like random forests and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_clf = make_pipeline(TfidfVectorizer(), LogisticRegression(random_state=0, max_iter=500))\n",
    "\n",
    "baseline_clf = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    RandomizedSearchCV(\n",
    "        LogisticRegression(random_state=0, max_iter=500),\n",
    "        {\n",
    "            \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "            \"tol\": loguniform(1e-5, 1e-3),\n",
    "            \"C\": uniform(loc=0, scale=4)\n",
    "        },\n",
    "        n_jobs=2, n_iter=100, cv=5,\n",
    "        scoring=\"f1_weighted\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "baseline_clf.fit(x_train, y_train);\n",
    "baseline_clf[\"randomizedsearchcv\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_clf = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# naive_bayes_clf = make_pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     RandomizedSearchCV(\n",
    "#         MultinomialNB(),\n",
    "#         {\n",
    "#             \"alpha\": uniform(0, 3),\n",
    "#             \"fit_prior\": [True, False]\n",
    "#         },\n",
    "#         n_jobs=2,\n",
    "#         scoring=\"f1_weighted\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "naive_bayes_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_neighbors_clf = make_pipeline(TfidfVectorizer(), KNeighborsClassifier())\n",
    "\n",
    "# k_nearest_neighbors_clf = make_pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     RandomizedSearchCV(\n",
    "#         KNeighborsClassifier(),\n",
    "#         {\n",
    "#             \"n_neighbors\": uniform(5, 10),\n",
    "#             \"weights\": [\"uniform\", \"distance\"],\n",
    "#             \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "#         },\n",
    "#         n_jobs=2,\n",
    "#         scoring=\"f1_weighted\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "k_nearest_neighbors_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_clf = make_pipeline(TfidfVectorizer(), DecisionTreeClassifier(random_state=0))\n",
    "\n",
    "# decision_tree_clf = make_pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     RandomizedSearchCV(\n",
    "#         RandomForestClassifier(random_state=0),\n",
    "#         {\n",
    "#             \"criterion\": [\"gini\", \"entropy\"]\n",
    "#             \"max_depth\": [None, randint(5, 50)],\n",
    "#             \"min_samples_split\": randint(2, 5),\n",
    "#             \"min_samples_leaf\": randint(2, 5)\n",
    "#         },\n",
    "#         n_jobs=2,\n",
    "#         scoring=\"f1_weighted\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "decision_tree_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = make_pipeline(TfidfVectorizer(), RandomForestClassifier(random_state=0))\n",
    "\n",
    "# random_forest_clf = make_pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     RandomizedSearchCV(\n",
    "#         RandomForestClassifier(random_state=0),\n",
    "#         {\n",
    "#             \"n_estimators\": randint(2, 100),\n",
    "#             \"max_depth\": [None, randint(5, 50)],\n",
    "#             \"min_samples_split\": randint(2, 5),\n",
    "#             \"min_samples_leaf\": randint(2, 5)\n",
    "#         },\n",
    "#         n_jobs=2,\n",
    "#         scoring=\"f1_weighted\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "random_forest_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosted_clf = make_pipeline(TfidfVectorizer(), GradientBoostingClassifier(n_estimators=10, max_features=200, max_depth=200, random_state=0))\n",
    "gradient_boosted_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_boosted_clf = make_pipeline(TfidfVectorizer(), XGBClassifier(max_depth=500, eta=1, gamma=1, min_child_weight=1, use_label_encoder=False))\n",
    "\n",
    "xg_boosted_clf = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    RandomizedSearchCV(\n",
    "        XGBClassifier(random_state=0, use_label_encoder=False),\n",
    "        {\n",
    "            \"max_depth\": [None, randint(5, 100)],\n",
    "            \"gamma\": randint(0, 5),\n",
    "            \"eta\": uniform(0, 1),\n",
    "            \"min_child_weight\": uniform(0, 2),\n",
    "            \"max_delta_step\": randint(0, 5)\n",
    "        },\n",
    "        n_jobs=2,\n",
    "        scoring=\"f1_weighted\"\n",
    "    )\n",
    ")\n",
    "\n",
    "xg_boosted_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "To evaluate how good our models are we will start by formulating a baseline estimate of how good a basic logistic regression model performs.\n",
    "We will look at the F1 score (which weighs precision and recall) and plot the confusion matrix.\n",
    "This will be repeated for each additional model.\n",
    "\n",
    "We will evaluate all our models, but due to the added time required to run cross validation, it is only used for the logistic regression baseline and best random forest model.\n",
    "This will output the accuracy over five seperate dataset folds to statistically ensure that the results are not an annomaly, nor cherry picked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_pipeline):\n",
    "    predictions = model_pipeline.predict(x_test)\n",
    "    f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "    report = classification_report(y_test, predictions)\n",
    "    \n",
    "    plot_confusion_matrix(model_pipeline, x_test, y_test);\n",
    "    \n",
    "    return f1, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(baseline_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(baseline_clf, x_resampled[\"content\"], y_resampled, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(naive_bayes_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(k_nearest_neighbors_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(decision_tree_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(random_forest_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(random_forest_clf, x_resampled[\"content\"], y_resampled, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(gradient_boosted_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, report = evaluate_model(xg_boosted_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "Out of all the models we can clearly see that our models all have similar precision and recall scores.\n",
    "This can be seen in the classification reports which show a variety of metrics (all usually with similar scores).\n",
    "For robustness though the F1 score shall be used to decipher which models perform best.\n",
    "\n",
    "\n",
    "We can empirically see that basic logistic regression models perform with around ~40 accuracy.\n",
    "The confusion matrix has both a bright diagonal and horizontal line.\n",
    "The horizontal line at four indicates that average scores are being predicted more than anything else, despite the fact that we are working with reballanced data.\n",
    "This is likely because there is a maximum amount of over sampling which can happen.\n",
    "Although it is not shown here, substituting the oversampled training dataset with the original unaltered one will result in this to an extreme extent where the enumber four is almost the only the number predicted.\n",
    "\n",
    "\n",
    "From the confusion matrix it is obvious that both Naive Bays and K-Nearest Neighbours classifiers have the exact same problem.\n",
    "Although the problem is slightly exagerated in Naive Bays, K-Nearest Neighbours has predicts top scorers far more accuratly.\n",
    "\n",
    "\n",
    "On the other hand, decision trees and random forests completely avoid the problem of predicting average scores far more frequently than anything else.\n",
    "These models still struggle to predict high-scoring responses.\n",
    "This can be read from the numbers, however is not visilbe in the confusion matrix due to the lack off data at these extremes.\n",
    "Note that this is a problem with the underlying dataset and not the models here.\n",
    "\n",
    "\n",
    "The boosting methods (ADA and Gradient) here perform very poorly.\n",
    "This can be further confirmed by rerunning the notebook with different numbers of models within their ensembles.\n",
    "The results being far worse in every metric than the baseline logistic regression emphasises the fact that the underlying data is not complex enough to use these boosted methods.\n",
    "Overfitting has likely occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "3c7d52aad02ab102b93569f413756f9f24e92e7f2578c445b4dc92137719a7a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
